{
 "cells": [
  {
   "cell_type": "raw",
   "id": "cdaa2f12-824d-45fa-ba5e-95efb338268e",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"Let Me Try to Explain LangChain\"\n",
    "description: \"Jenn's teacher-hat-mode-initiated\"\n",
    "author: \"Jenn Deng\"\n",
    "date: \"2/24/2024\"\n",
    "categories:\n",
    "  - LLMs\n",
    "  - prompting\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdbf3ddc-9630-40d2-86e2-78ed06349822",
   "metadata": {},
   "source": [
    "# What is the term **large language model**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f98317c-ebc5-4b81-9948-912694f78e5f",
   "metadata": {},
   "source": [
    "<img src=\"1.png\" width=\"100%\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fdf06ed-b81d-4600-bd9a-580e857047ad",
   "metadata": {},
   "source": [
    "**Large Language Models:** </br>\n",
    "- *Large* describes the size of these models based on the training data and parameters.\n",
    "- *Language model* describes the computer algorithm trained to receive written text and to create an output.\n",
    "- Large language models are trained on vast amounts of text and have learned from the patterns in large data sets.\n",
    "\n",
    "**Fun Fact** : Most models are better at English than they are in other languages because of the prevalence of English in training models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21681d20-4ba2-4768-9622-b10a49a8f81f",
   "metadata": {},
   "source": [
    "# How Does LangChain Come Into Play"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61d2bb4a-1a79-4f98-bda8-e7e69612a543",
   "metadata": {},
   "source": [
    "<img src=\"2.png\" width=\"100%\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60c2c8c6-474f-4929-9efe-ccc7b081b0fa",
   "metadata": {},
   "source": [
    "On October 22, 2022, Harrison Chase was the first the publish the first commit on GitHub for the LangChain open source library. </br>\n",
    "LangChain was created after  discovering that LLM applications needed to use LLMs together with \"other sources of computation or knowledge\". </br>\n",
    "It creates simple abstractions for each major prompting technique.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb5aa6c2-ccb6-450e-b52f-677d7a0a9b43",
   "metadata": {},
   "source": [
    "# Getting Set Up With LangChain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad5c018c-bffe-4f3b-957e-916777c59823",
   "metadata": {},
   "source": [
    "I'll be referencing O'Reilly \"Chapter 1.LLM Fundementals With LangChain\" if you want to follow along! We're going to learn how to work with LangChain's building blocks to understand more about LLM concepts. </br>\n",
    "LangChain has two interfaces to interact with any LLM API provider\n",
    "- Chat models\n",
    "- LLMS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01a484d7-715d-4898-9ea8-cc050c8b1d8b",
   "metadata": {},
   "source": [
    "##### **Example 1: I'm at a Capital One..\"**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "677d0915-b46f-47cd-af59-d1624d164523",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e0984092-186d-4c37-9faa-c1511add47b2",
   "metadata": {},
   "source": [
    "```{details}\n",
    "from langchain_openai.chat_models import ChatOpenAI\n",
    "\n",
    "model = ChatOpenAI(model=\"gpt-3.5-turbo\")\n",
    "\n",
    "response = model.invoke(\"I'm at a capital one\")\n",
    "print(response)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2d44ed13-436e-4c3c-afed-f062d99c774c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='bank branch. How can I assist you today?' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 11, 'prompt_tokens': 13, 'total_tokens': 24, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None} id='run-80a164c8-60dd-447f-a128-6e6482c0df04-0' usage_metadata={'input_tokens': 13, 'output_tokens': 11, 'total_tokens': 24, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai.chat_models import ChatOpenAI\n",
    "\n",
    "model = ChatOpenAI(model=\"gpt-3.5-turbo\")\n",
    "\n",
    "response = model.invoke(\"I'm at a capital one\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcddcac9-24fb-4ce1-82ab-cb096e4be2db",
   "metadata": {},
   "outputs": [],
   "source": [
    "R"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3-12 (COMM4190)",
   "language": "python",
   "name": "python3-12_comm4190"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
