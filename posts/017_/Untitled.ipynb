{
 "cells": [
  {
   "cell_type": "raw",
   "id": "ebfe8712-ac20-4abb-8bfa-2eae7e8cf436",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"Movie Suggestions?: Testing Out Google Prompt Engineering Guide\"\n",
    "description: \"Which prompting technique works best?\"\n",
    "author: \"Jenn Deng\"\n",
    "date: \"05/07/2025\"\n",
    "categories:\n",
    "  - LLMs\n",
    "  - prompting\n",
    "  - methods \n",
    "  - movie suggestions\n",
    "  - Google!\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "481fcc20-88ee-4ee6-a821-3b46b36d4bcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "Google claims that \"prompt enginnering can help you be more productive "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd6e70bd-b72a-4591-bea2-ce877145f442",
   "metadata": {},
   "outputs": [],
   "source": [
    "means using natural language to command a large language model "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1f03025-2e70-4887-995d-dc797d8f65b2",
   "metadata": {},
   "source": [
    "Google's **Tips to Becoming a World-Class Prompt Engineeer**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "043e588b-b464-4182-86d1-7849b45e68b5",
   "metadata": {},
   "source": [
    "<img src=\"1.png\" width=90%/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed984bb5-c1da-48a3-a0ac-dbfd56bd8ea7",
   "metadata": {},
   "source": [
    "# Google recently released a 69 page paper on prompt engineering and there are 11 ways it categorizes prompting methods "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18fc20a3-22c7-4dc1-9d64-402e3cf82f43",
   "metadata": {},
   "source": [
    "1. Direct Prompts (Zero-shot) </br>\n",
    "\n",
    "This type of prompting doesn't provide any additional context or examples, but just provides the model with a direct instruction or question."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22d55cfd-e250-4ebc-bbfd-2332f8aea0b9",
   "metadata": {},
   "source": [
    "2. One-, few- and multi-shot prompts </br>\n",
    "\n",
    "This method involves providing the model with one or more examples of the desired input-output pars before presenting the actual prompt .This can help the model better understand the task and generate more accurate responses."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94ca699b-a163-4c8f-99b8-07b546f0fff4",
   "metadata": {},
   "source": [
    "3. Chain of Thought Prompts  </br>\n",
    "\n",
    "CoT prompting encourages the model to break down complex reasoninig into a series of intermediate steps, leading to a more comprehensive and wellstructured final output."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8df1cfeb-4d9f-4a0c-a125-19a2b7c19611",
   "metadata": {},
   "source": [
    "4. Zero-shot CoT Prompts </br>\n",
    "\n",
    "Combines chain of thought prompting with zero-shot prompting by asking the model to perform reasoning steps, which may often produce better output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fefe71e1-4b7f-4102-9c1c-bd2c2458fa7b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3-12 (COMM4190)",
   "language": "python",
   "name": "python3-12_comm4190"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
