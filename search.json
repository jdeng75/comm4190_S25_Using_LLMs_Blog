[
  {
    "objectID": "posts/002_Dinner_Suggestions/index2.html",
    "href": "posts/002_Dinner_Suggestions/index2.html",
    "title": "Guestimation and Making Graphs in R!",
    "section": "",
    "text": "Guestimation and Making Graphs in R\n\nI also want to learn how to code more in R, and I really like graphs\nI’m going to ask ChatGPT if they can give me code to make graphs.\nThese questions will be guestimations on what ChatGPT thinks of certain trend lines.\n\n\nLet’s cook.\n\n1. Years Lived vs Amount of Friends\n\nJenn asks: Can you create R code for a graph to show your guestimation on years lived vs amount of friends.\n\n\nChatGPT:\n \n\n\nWhen I asked why there was this trend, ChatGPT responded with &gt; The trend I used in the R code is based on general social patterns observed in human friendships over a lifetime. Here’s why I shaped it that way: &gt;1. Friendships Peak in Young Adulthood (20s-30s) People tend to have the most friends in their teens and 20s, especially in school, university, or early careers. Social environments like college, sports, clubs, and workplaces provide many opportunities for new friendships. There’s generally more free time for social activities before major life commitments (e.g., demanding careers, marriage, parenting). &gt;2. Gradual Decline in Middle Age (30s-50s) In the 30s and 40s, people often prioritize careers, families, and personal responsibilities, leading to less time for socializing. Some friendships naturally fade due to geographical moves, lifestyle changes, or shifting priorities. However, a smaller core group of close friends often remains. &gt;3. Further Decline in Older Age (60s-80s) Retirement, health issues, and the loss of peers contribute to fewer active friendships. Many elderly people rely more on family, close lifelong friends, or community groups rather than maintaining large social circles. Some older adults reconnect with old friends or develop new friendships in retirement communities, but the overall trend is downward. &gt; Why This Trend Makes Sense? Social networks are largest in early adulthood when we have high social mobility and opportunity. Life responsibilities impact time and effort spent on friendships as we grow older. Aging naturally reduces social engagement, with some maintaining strong bonds but a smaller total number of friends. Of course, this is a generalization—individual experiences vary widely! Some people maintain or even expand their social circles in later years. Would you like me to adjust the model to include different factors, such as personality types or social media influence?\nAnd honestly, I think their prediction and trend line is correct. Let us move on…\n\n\n\n2. Age vs Breast Cancer Rates\n\nJenn asks: and can you write code for age vs breast cancer rates &gt; ChatGPT: &gt; &gt;  &gt; \nWhen I ask why they think it exhibits this trend: &gt; Why This Trend? &gt; Young women (20-30s): Very low breast cancer rates. Middle age (40-50s): Rates begin to rise due to hormonal and genetic factors. Older age (60-80s): Highest incidence rates, as risk accumulates over time. This is a simplified model based on general trends seen in epidemiology. Would you like a more specific model with real-world data, or adjustments to include factors like genetic risk?"
  },
  {
    "objectID": "posts/001_Drawing_post/index1.html",
    "href": "posts/001_Drawing_post/index1.html",
    "title": "Posting Pictures for ChatGPT",
    "section": "",
    "text": "Posting Pictures for ChatGPT\n\nIn this blog post, I will be uploading pictures to ChatGPT.\nThis experiment is to see whether ChatGPT can accurately describe the scene.\n\n\n1. Picture of a Switzerland Keychain\n\nJenn: “Can you describe what this photo is to me? And what this object is?”\n\n\n\nChatGPT: This photo shows a person wearing black gloves holding a keychain. The keychain is heart-shaped and made of wood, featuring an illustration of Interlaken, Switzerland. It has the Swiss flag on it, along with mountains and buildings, likely representing the scenic landscape of the town. The keychain is attached to a metal ring for keys.The packaging label at the top is red, displaying the brand name Alberto SA. It has a barcode and a price tag indicating Fr. 8.– (Swiss Francs). The background suggests a store setting, possibly a souvenir shop, with other keychains and items on display.\n\n\nJenn’s Observations: I think ChatGPT was able to accurately describe the picture!\n\n\n\n2. Picture of ‘Babel’ at Tate Modern in London\n\nJenn: “Can you tell me who made this, what it is, where it’s located, and why it was created?”\n\n\n\nChatGPT: Yes! This is a well-known art installation called Babel by the artist Cildo Meireles. What is it?: Babel is a towering installation made from hundreds of stacked radios from different time periods and styles. The radios are arranged in a cylindrical structure, with some turned on and emitting faint sounds, creating a layered auditory experience. Where is it located?: It is part of the collection at the Tate Modern in London, though it may be exhibited elsewhere in temporary installations. Why was it created?: Cildo Meireles created Babel as a commentary on communication, information overload, and miscommunication in the modern world. The name refers to the Biblical Tower of Babel, a story in which human ambition to reach the heavens led to the confusion of languages, causing people to be unable to understand each other. Similarly, the installation suggests the overwhelming and often chaotic nature of mass communication today. If you saw this in a different museum, it could be on loan or part of a traveling exhibition!\n\n\nJenn’s Observations: It’s interesting how ChatGPT was still able to detect that it was Babel, even though there was a person who was in the way of the art piece. I liked how it mentions that if I saw it at a different museum that it was probably apart of a traveling exhibition.\n\n\n\n3. Picture of one side of the Sagrada Familia\n\nJenn: “What is this, where is this, who created it, and why was it created?”\n\n\n\nChatGPT: This is a photo of the interior of the Sagrada Família, a world-famous basilica located in Barcelona, Spain. What is this? The image captures the breathtaking stained glass windows and organic, tree-like columns inside the Sagrada Família. The interplay of natural light and vibrant colors is a hallmark of this architectural masterpiece. Who created it? The Sagrada Família was designed by the renowned Catalan architect Antoni Gaudí. Construction began in 1882, and it remains unfinished to this day, with ongoing work continuing in accordance with Gaudí’s vision. Why was it created? Gaudí envisioned the Sagrada Família as a deeply spiritual and symbolic structure, blending Gothic and Art Nouveau styles with naturalistic forms. The basilica was created as a place of worship and devotion, meant to inspire awe and reflect Christian faith through architecture. The organic, tree-like columns, geometric details, and stained glass windows were all meticulously designed to create a harmonious and immersive experience. It is one of the most visited landmarks in the world and a UNESCO World Heritage Site, drawing millions of visitors annually. The goal is to complete its construction by 2032, marking the 150th anniversary of Gaudí’s death.\n\n\nJenn’s Observations: Even though I only showed a small portion, ChatGPT was still able to guess the location accurately. I am impressed.\n\n\nOverall, I am impressed by how accurate ChatGPT was when trying to guess what objects/places were in my photos. Perhaps next time, I will try to draw pictures (horribly) to see if ChatGPT can decipher my images."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this blog"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "My Explorations with LLMs",
    "section": "",
    "text": "Posting Pictures for ChatGPT\n\n\n\n\n\n\nLLMs\n\n\nprompting\n\n\nlogic\n\n\n\nLet’s see if ChatGPT can guess correctly!\n\n\n\n\n\nFeb 3, 2024\n\n\nJenn Deng\n\n\n\n\n\n\n\n\n\n\n\n\nAI Hallucinations\n\n\n\n\n\n\nLLMs\n\n\nprompting\n\n\nlogic\n\n\n\nnot everything is correct!\n\n\n\n\n\nFeb 3, 2024\n\n\nJenn Deng\n\n\n\n\n\n\n\n\n\n\n\n\nGuestimation and Making Graphs in R!\n\n\n\n\n\n\nLLMs\n\n\nprompting\n\n\n\nLet’s cook.\n\n\n\n\n\nFeb 3, 2024\n\n\nJenn Deng\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/003_AI_Hallucination/index3.html",
    "href": "posts/003_AI_Hallucination/index3.html",
    "title": "AI Hallucinations",
    "section": "",
    "text": "Hallucinations in AI happens when there are incorrect or misleading results generated by AI models. This happens when an AI system makes false assumptions or uses biased data to generate information. &gt; How do hallucinations happen? &gt; * not enough training data &gt; * biased training data &gt; * wrong assumptions &gt; * processing errors\nSometimes, there’s wrong code or images that pop up. It’s up to us to choose whether the information is right or wrong. Let’s look at a few examples that a few people have encountered in the past.\n\n\n\n\nI took a quick look on Reddit to dig for some examples of ChatGPT hallucinations. I wanted to see if they still existed, since some of the posts were 1-2 years ago.\n\n\n\n Jenn’s update: Well, I think they fixed this up. \n\n\n\nOk, well… let’s check on Reddit for some more ChatGPT hallucinations\n\n\n\n Jenn’s update: It’s interesting how they try to reference the information, but still got the information wrong. \n\n\n\nAh-HAH! One down. Let’s try another one. Now, I’m not an organic chemistry person, but let’s see if this one has updated from 2 years ago.\n\n\n\n Jenn’s update: Well, darn! This is sad for any organic chemistry lovers out there. ChatGPT is really bad at organic chemistry."
  },
  {
    "objectID": "posts/003_AI_Hallucination/index3.html#ai-hallucinations",
    "href": "posts/003_AI_Hallucination/index3.html#ai-hallucinations",
    "title": "AI Hallucinations",
    "section": "",
    "text": "Hallucinations in AI happens when there are incorrect or misleading results generated by AI models. This happens when an AI system makes false assumptions or uses biased data to generate information. &gt; How do hallucinations happen? &gt; * not enough training data &gt; * biased training data &gt; * wrong assumptions &gt; * processing errors\nSometimes, there’s wrong code or images that pop up. It’s up to us to choose whether the information is right or wrong. Let’s look at a few examples that a few people have encountered in the past.\n\n\n\n\nI took a quick look on Reddit to dig for some examples of ChatGPT hallucinations. I wanted to see if they still existed, since some of the posts were 1-2 years ago.\n\n\n\n Jenn’s update: Well, I think they fixed this up. \n\n\n\nOk, well… let’s check on Reddit for some more ChatGPT hallucinations\n\n\n\n Jenn’s update: It’s interesting how they try to reference the information, but still got the information wrong. \n\n\n\nAh-HAH! One down. Let’s try another one. Now, I’m not an organic chemistry person, but let’s see if this one has updated from 2 years ago.\n\n\n\n Jenn’s update: Well, darn! This is sad for any organic chemistry lovers out there. ChatGPT is really bad at organic chemistry."
  }
]